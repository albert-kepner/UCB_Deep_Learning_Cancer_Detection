{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454da935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e7zv5qo\\Jupyter_Notebooks\\UCB_Deep_Learning_03\\Module3\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys \n",
    "import zipfile\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "def scale_image(image1):\n",
    "    im = image1.astype(np.float32)\n",
    "    im /= 255\n",
    "    return im\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "537528f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              id  label\n",
      "0       f38a6374c348f90b587e046aac6079959adf3835      0\n",
      "1       c18f2d887b7ae4f6742ee445113fa1aef383ed77      1\n",
      "2       755db6279dae599ebb4d39a9123cce439965282d      0\n",
      "3       bc3f0c64fb968ff4a8bd33af6971ecae77c75e08      0\n",
      "4       068aba587a4950175d04c680d38943fd488d6a9d      0\n",
      "...                                          ...    ...\n",
      "220020  53e9aa9d46e720bf3c6a7528d1fca3ba6e2e49f6      0\n",
      "220021  d4b854fe38b07fe2831ad73892b3cec877689576      1\n",
      "220022  3d046cead1a2a5cbe00b2b4847cfb7ba7cf5fe75      0\n",
      "220023  f129691c13433f66e1e0671ff1fe80944816f5a2      0\n",
      "220024  a81f84895ddcd522302ddf34be02eb1b3e5af1cb      1\n",
      "\n",
      "[220025 rows x 2 columns]\n",
      "['f38a6374c348f90b587e046aac6079959adf3835.tif', 'c18f2d887b7ae4f6742ee445113fa1aef383ed77.tif', '755db6279dae599ebb4d39a9123cce439965282d.tif', 'bc3f0c64fb968ff4a8bd33af6971ecae77c75e08.tif', '068aba587a4950175d04c680d38943fd488d6a9d.tif']\n"
     ]
    }
   ],
   "source": [
    "train_labels = pd.read_csv(\"./data/train_labels.csv\")\n",
    "print(train_labels)\n",
    "train_images = list(train_labels['id'])\n",
    "train_images = [ name + '.tif' for name in train_images]\n",
    "labels = list(train_labels['label'])\n",
    "print(train_images[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc08fce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210000\n",
      "210000\n",
      "10025\n",
      "10025\n",
      "[1, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "0.40503124644926713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_images, labels, random_state=0, train_size = 210000)\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_valid))\n",
    "print(len(y_valid))\n",
    "print(y_train[0:10])\n",
    "print(np.mean(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db9e806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_collection(file_list, file_path):\n",
    "    return np.array([\n",
    "        scale_image(imread(file_path+file_name))\n",
    "        for file_name in file_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72dd5c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b39869928d6bcdc4c3be03ac34b781186814a929.tif', 'c667053b8177533b69710ac12671a494f3446e74.tif', 'a265cdfc83c4c961bc4186638a3564dd5bb86c1c.tif', '8eb04aba813097c3abd141016eb6d3fd065dcd7a.tif', '1013bc0def9e87f75af3a2f9bfa6e3a2ccb7f732.tif']\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e91a1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210000, 96, 96, 3)\n",
      "(10025, 96, 96, 3)\n",
      "Ready\n"
     ]
    }
   ],
   "source": [
    "X_train_images = read_image_collection(X_train, './data/train/')\n",
    "print(X_train_images.shape)\n",
    "X_valid_images = read_image_collection(X_valid, './data/train/')\n",
    "print(X_valid_images.shape)\n",
    "print('Ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7b5ea9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.22432\n"
     ]
    }
   ],
   "source": [
    "gbytes = 210000 * 96 * 96 * 3 * 4/ 10**9\n",
    "print(gbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb6258dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 94, 94, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 45, 45, 48)        13872     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 22, 22, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 20, 20, 64)        27712     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 454,257\n",
      "Trainable params: 454,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "def modelArch4():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(32, 3, activation='relu', padding='valid',\n",
    "                           input_shape=[96,96,3]),\n",
    "        keras.layers.MaxPool2D(2),\n",
    "        keras.layers.Conv2D(48, 3, activation=tf.nn.relu, padding='valid'),\n",
    "        keras.layers.MaxPool2D(2),\n",
    "        keras.layers.Conv2D(64, 3, activation=tf.nn.relu, padding='valid'),\n",
    "        keras.layers.MaxPool2D(2),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(32,  activation=tf.nn.relu),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = modelArch4()\n",
    "model.summary()\n",
    "opt = keras.optimizers.Adam(learning_rate=0.00020)\n",
    "loss = keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "771119f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "6563/6563 [==============================] - 807s 123ms/step - loss: 0.4683 - accuracy: 0.7910 - val_loss: 0.3609 - val_accuracy: 0.8468\n",
      "Epoch 2/2\n",
      "6563/6563 [==============================] - 788s 120ms/step - loss: 0.3637 - accuracy: 0.8496 - val_loss: 0.3084 - val_accuracy: 0.8717\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train_images,y=np.array(y_train),verbose=1,validation_data=(X_valid_images,np.array(y_valid)),epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ab108a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6563/6563 [==============================] - 794s 121ms/step - loss: 0.3120 - accuracy: 0.8750 - val_loss: 0.2565 - val_accuracy: 0.8934\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train_images,y=np.array(y_train),verbose=1,validation_data=(X_valid_images,np.array(y_valid)),epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "233682d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6563/6563 [==============================] - 818s 125ms/step - loss: 0.2767 - accuracy: 0.8916 - val_loss: 0.2659 - val_accuracy: 0.8897\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train_images,y=np.array(y_train),verbose=1,validation_data=(X_valid_images,np.array(y_valid)),epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da1354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=X_train_images,y=np.array(y_train),verbose=1,validation_data=(X_valid_images,np.array(y_valid)),epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08ffad5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0b2ea2a822ad23fdb1b5dd26653da899fbd2c0d5.tif',\n",
       " '95596b92e5066c5c52466c90b69ff089b39f2737.tif',\n",
       " '248e6738860e2ebcf6258cdc1f32f299e0c76914.tif',\n",
       " '2c35657e312966e9294eac6841726ff3a748febf.tif',\n",
       " '145782eb7caa1c516acbe2eda34d9a3f31c41fd6.tif',\n",
       " '725dabe6ecccc68b958a2c7dd75bcbf362c7cb03.tif',\n",
       " 'aa0307865281d4484ddf8c637c348292968b93a7.tif',\n",
       " 'f4e5dc9c949920f1b3362982e15e99bf6f3ef83b.tif',\n",
       " '95e08c9cedc28a9b4a86f4fc1e06c1972134be08.tif',\n",
       " 'ee1f5345a8d4e28403b7e61b97b5f76c201ce9cb.tif']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv('./data/sample_submission.csv')\n",
    "sample_names = list(sample['id'])\n",
    "sample_names[0:20]\n",
    "## train_images = [ name + '.tif' for name in train_images]\n",
    "test_images = [name + '.tif' for name in sample_names]\n",
    "test_images[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9712e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57458, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "X_test_images = read_image_collection(test_images, './data/test/')\n",
    "print(X_test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "045d6976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57458, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9864c413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01387101]\n",
      " [0.728766  ]\n",
      " [0.00339532]\n",
      " [0.13174924]\n",
      " [0.02223381]\n",
      " [0.7158254 ]\n",
      " [0.9858694 ]\n",
      " [0.8292243 ]\n",
      " [0.38539946]\n",
      " [0.64895415]]\n",
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n",
      "[23456]\n",
      "57458\n",
      "Submission 14\n"
     ]
    }
   ],
   "source": [
    "## predictions = (model.predict(X_test_images) > 0.5).astype(\"int32\")\n",
    "predict_proba = model.predict(X_test_images)\n",
    "## predictions[0:10]\n",
    "print(predict_proba[0:10])\n",
    "predictions = (predict_proba > 0.5).astype(\"int32\")\n",
    "print(predictions[0:10])\n",
    "print(sum(predictions))\n",
    "print(len(predictions))\n",
    "df = pd.DataFrame(sample_names)\n",
    "df.columns= ['id']\n",
    "df['label'] = predictions\n",
    "df\n",
    "df.to_csv('./data/submission14.csv',index=False)\n",
    "print('Submission 14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd2e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
